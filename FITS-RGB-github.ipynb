{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Loading solar wind speed data\n",
    "\n",
    "from __future__ import print_function\n",
    "#dataset after preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sklearn\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "#speed values_2013\n",
    "\n",
    "data_2013=pd.read_csv(\"/home/hemapriya/hema_data/sw_speed_2013_18/2013_sw_speed.csv\")  ####change location\n",
    " \n",
    "\n",
    "#speedvalues\n",
    "data_y_2013=data_2013[72:4380]\n",
    "duration_2013=data_y_2013.iloc[:,4].values\n",
    "data_speed_2013=data_y_2013.iloc[:,3].values \n",
    "print(data_y_2013.shape)\n",
    "\n",
    "#speed values_2014\n",
    "\n",
    "data_2014=pd.read_csv(\"/home/hemapriya/hema_data/sw_speed_2013_18/2014_sw_speed.csv\")  ####change location\n",
    " \n",
    "\n",
    "#speedvalues\n",
    "data_y_2014=data_2014[49:4380]\n",
    "duration_2014=data_y_2014.iloc[:,4].values\n",
    "data_speed_2014=data_y_2014.iloc[:,3].values \n",
    "\n",
    "#speed values_2015\n",
    "\n",
    "data_2015=pd.read_csv(\"/home/hemapriya/hema_data/sw_speed_2013_18/sw_speed_2015.csv\")  ####change location\n",
    " \n",
    "\n",
    "#speedvalues\n",
    "data_y_2015=data_2015[49:4380]\n",
    "duration_2015=data_y_2015.iloc[:,4].values\n",
    "data_speed_2015=data_y_2015.iloc[:,3].values \n",
    "\n",
    "\n",
    "\n",
    "#speed values 2017 \n",
    "data=pd.read_csv(\"/home/hemapriya/hema_data/sw_speed_2013_18/solar_wind_latest_2017.csv\")  ####change location\n",
    " \n",
    "\n",
    "#speedvalues\n",
    "data_y_2017=data[49:4380]\n",
    "duration=data_y_2017.iloc[:,4].values\n",
    "data_speed=data_y_2017.iloc[:,3].values \n",
    "\n",
    "#speed_values_2018\n",
    "data_2018=pd.read_csv(\"/home/hemapriya/hema_data/sw_speed_2013_18/sw_speed_2018.csv\")  ####change location\n",
    " \n",
    "\n",
    "#speedvalues\n",
    "data_y_2018=data_2018[49:4380]\n",
    "data_2018_1=data_2018.iloc[:,3].values\n",
    "duration_2018=data_y_2018.iloc[:,4].values\n",
    "data_speed_2018=data_y_2018.iloc[:,3].values \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#merging all data\n",
    "\n",
    "train_y1=data_y_2013.append(data_y_2014)\n",
    "train_y2=train_y1.append(data_y_2015)\n",
    "train_y3=train_y2.append(data_y_2017)\n",
    "#train_y1=train_y_inter.append(data_y_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy_speed=train_y3.iloc[:,3].values\n",
    "trainy_speed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## log scaling method and Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_process(data):\n",
    "    tmp = np.log10(data+1e-5)\n",
    "    min1 = np.min(data)\n",
    "\n",
    "    scale_min=500/4.0 #Was 500/4.0\n",
    "    scale_max=20000/4.0 \n",
    "    tmp[np.where(tmp<np.log10(scale_min+min1))] = np.log10(scale_min+min1) \n",
    "    tmp[np.where(tmp>np.log10(scale_max+min1))] = np.log10(scale_max+min1)\n",
    "    minimum_new = np.min(tmp)\n",
    "    maximum_new = np.max(tmp)\n",
    "    tmp = (tmp-minimum_new)*256.0/(maximum_new-minimum_new)\n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file1_2013=glob.glob(\"/home/hemapriya/ML_SDO/2013/mm_cp/AIA2013*.npz\")\n",
    "print(len(images_file1_2013))\n",
    "images_file_2013=sorted(images_file1_2013)\n",
    "images_updated_2013=[]\n",
    "i=72\n",
    "while i<4380:\n",
    "    images_updated1_2013=images_file_2013[(i)-(int(round(duration_2013[i-72]))*12)]\n",
    "    images_updated_2013.append(images_updated1_2013)\n",
    "    i+=1\n",
    "images_train=[]\n",
    "for f in images_updated_2013:\n",
    "    data_2013=np.load(f)\n",
    "    g=np.array(data_2013['x'])\n",
    "    im_2013=image_process(g) \n",
    "    images_train.append(im_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file1_2014=glob.glob(\"/home/hemapriya/ML_SDO/2014/mm_cp/AIA2014*.npz\")   ####change location\n",
    "print(len(images_file1_2014))\n",
    "images_file_2014=sorted(images_file1_2014)\n",
    "images_updated_2014=[]\n",
    "i=49\n",
    "while i<4380:\n",
    "    images_updated1_2014=images_file_2014[(i)-(int(round(duration_2014[i-49]))*12)]\n",
    "    images_updated_2014.append(images_updated1_2014)\n",
    "    i+=1\n",
    "for f in images_updated_2014:\n",
    "    data_2014=np.load(f)\n",
    "    g_2014=np.array(data_2014['x'])\n",
    "    im_2014=image_process(g_2014) \n",
    "    images_train.append(im_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015\n",
    "\n",
    "images_file1_2015=glob.glob(\"/home/hemapriya/ML_SDO/2015/mm_cp/AIA2015*.npz\")   ####change location\n",
    "print(len(images_file1_2015))\n",
    "images_file_2015=sorted(images_file1_2015)\n",
    "images_updated_2015=[]\n",
    "k=49\n",
    "while k<4380:\n",
    "    images_updated1_2015=images_file_2015[(k)-(int(round(duration_2015[k-49]))*12)]\n",
    "    images_updated_2015.append(images_updated1_2015)\n",
    "    k+=1\n",
    "for f in images_updated_2015:\n",
    "    data_2015=np.load(f)\n",
    "    g_2015=np.array(data_2015['x'])\n",
    "    im_2015=image_process(g_2015) \n",
    "    images_train.append(im_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017\n",
    "images_file1=glob.glob(\"/home/hemapriya/ML_SDO/2017/mm_cp/AIA2017*.npz\")   ####change location\n",
    "images_file=sorted(images_file1)\n",
    "images_updated=[]\n",
    "i=49\n",
    "while i<4380:\n",
    "    images_updated1=images_file[(i)-(int(round(duration[i-49]))*12)]\n",
    "    images_updated.append(images_updated1)\n",
    "    i+=1\n",
    "for f in images_updated:\n",
    "    data_2017=np.load(f)\n",
    "    g_2017=np.array(data_2017['x'])\n",
    "    im_2017=image_process(g_2017) \n",
    "    images_train.append(im_2017)\n",
    "np.save('/DATA/hemapriya/data/train_images_2021_logn_t10.npy',images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "images_file1_2018=glob.glob(\"/home/hemapriya/ML_SDO/2018/mm_cp/AIA2018*.npz\")   ####change location\n",
    "images_file_2018=sorted(images_file1_2018)\n",
    "\n",
    "\n",
    "images_train_2018=[]\n",
    "for f in images_file_2018:\n",
    "    data_2018=np.load(f)\n",
    "    g_2018=np.array(data_2018['x'])\n",
    "    im_2018=image_process(g_2018) \n",
    "    images_train_2018.append(im_2018)\n",
    "np.save('/DATA/hemapriya/data/img_2018_logn_t10.npy',images_train_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Loading training data\n",
    "train_x=np.load('/home/hemapriya/ML_SDO/train_images_2021_logn.npy')\n",
    "data_x = train_x.reshape(train_x.shape[0], 512,512,1)\n",
    "print(data_x.shape)\n",
    "#LOading testing data\n",
    "test_2018=np.load('/home/hemapriya/ML_SDO/img_2018_logn.npy')\n",
    "test_x1 = test_2018.reshape(test_2018.shape[0], 512,512,1)\n",
    "test_x=test_x1[0:4331]\n",
    "print((test_x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_x[4050].reshape(512,512),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data randomly\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x1,val_x,train_y1,val_y=train_test_split(data_x,trainy_speed,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train_y1.shape)\n",
    "print(data_speed_2018.shape)\n",
    "print(val_y.shape)\n",
    "print(train_x1.shape)\n",
    "print(test_x.shape)\n",
    "print(val_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to clear space for gpu, if occupied by any process\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#CNN architecture\n",
    "\n",
    "#importing keras libraries\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import convolutional\n",
    "from keras.layers import pooling\n",
    "from keras.layers import core\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model_8 = Sequential()\n",
    "model_8.add(convolutional.Convolution2D(32, (9,9),strides=(3, 3), input_shape=(512,512,1)))\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(pooling.MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "model_8.add(convolutional.Convolution2D(64, (2,2),strides=(2, 2)))\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(pooling.MaxPooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
    "model_8.add(convolutional.Convolution2D(128, (2,2),strides=(2, 2)))\n",
    "model_8.add(BatchNormalization())\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(pooling.MaxPooling2D(pool_size=(3, 3),strides=(1, 1)))\n",
    "model_8.add(Flatten())\n",
    "model_8.add(Dense(4096,activation='relu'))\n",
    "model_8.add(core.Dropout(.3))\n",
    "model_8.add(Dense(1,activation='linear'))\n",
    "model_8.compile(optimizer=optimizers.Adam(lr=1e-04), loss='mse',metrics=['mse'])\n",
    "print(model_8.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dense1.dtype_policy)\n",
    "print('x.dtype: %s' % x.dtype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "#early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "history=model_8.fit(train_x1,train_y1,batch_size=128,epochs=7,validation_data=(val_x,val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting and plotting the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving weights\n",
    "#model_8.save_weights('/home/hemapriya/ML_SDO/models/train_weights_183l_frgb_4d.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8.load_weights('/home/hemapriya/ML_SDO/models/train_weights_183l_frgb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result=model_8.evaluate(y_test1,data_speed_2018,batch_size=128)\n",
    "print(\"test loss, test acc:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_val_1=model_8.predict(val_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val_1=pd.DataFrame(y_val_1)\n",
    "y_val_1.to_csv(r'/DATA/hemapriya/val_predicted.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2=pd.DataFrame(y_train1)\n",
    "\n",
    "y_train2.to_csv(r'/DATA/hemapriya/train_predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting CNN prediction for year 2018\n",
    "plt.figure(figsize=(25,7))\n",
    "plt.ylim(200,800)\n",
    "plt.plot((y_test1),label='predicted',linewidth=2.0)\n",
    "plt.plot(data_speed_2018,label='actual',linewidth=3.0)\n",
    "for i in icme_h:\n",
    "    plt.axvline(x=i,ymin=0.9, ymax=1,linewidth=5.0,color='green')\n",
    "plt.plot(np.NaN, np.NaN, color='green',linewidth=5.0, label='ICME')\n",
    "plt.title('CNN prediction for the year 2018',fontsize=30)\n",
    "plt.xlabel('days',fontsize=25,c='white')\n",
    "plt.ylabel('windspeed(Km/s)',fontsize=25,c='white')\n",
    "plt.legend(fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###visualiztion of activation\n",
    "\n",
    "import eli5\n",
    "expl = eli5.explain_prediction(model_8, test_x[1245].reshape(1,512,512,1))\n",
    "print((expl.targets[0].target, expl.targets[0].score, expl.targets[0].proba))\n",
    "image = expl.image\n",
    "heatmap = expl.targets[0].heatmap\n",
    "plt.subplots_adjust(left=0.5, bottom=0.5, right=None, top=None, wspace=0.9, hspace=0.9)\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image,cmap='gray')# the .image attribute is a PIL image\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "#overlaying heatmap over original image\n",
    "heatmap_im = eli5.formatters.image.heatmap_to_image(heatmap)\n",
    "plt.imshow(heatmap_im,cmap='viridis')\n",
    "I = eli5.format_as_image(expl)\n",
    "plt.imshow(I)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "print(y_test1[4286])\n",
    "print(data_speed_2018[4286])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Saving activation images for high speed and low speed,\n",
    "i=0\n",
    "while i < ((len(data_speed_2018))):\n",
    "        expl = eli5.explain_prediction(model_8, test_x[i].reshape(1,512,512,1))\n",
    "        print((expl.targets[0].target, expl.targets[0].score, expl.targets[0].proba))\n",
    "        image = expl.image\n",
    "        heatmap = expl.targets[0].heatmap\n",
    "        plt.subplots_adjust(left=0.5, bottom=0.5, right=None, top=None, wspace=0.9, hspace=0.9)\n",
    "        plt.figure(figsize=(9,9))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(image,cmap='gray')# the .image attribute is a PIL image\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        #overlaying heatmap over original image\n",
    "        heatmap_im = eli5.formatters.image.heatmap_to_image(heatmap)\n",
    "        plt.imshow(heatmap_im,cmap='viridis')\n",
    "        I = eli5.format_as_image(expl)\n",
    "        plt.imshow(I)\n",
    "\n",
    "        plt.colorbar(fraction=0.046, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        if data_speed_2018[i]>400:\n",
    "            plt.savefig('/home/hemapriya/ML_SDO/activation_images/hs/im_%s.jpg' %data_speed_2018[i])\n",
    "        else:\n",
    "            plt.savefig('/home/hemapriya/ML_SDO/activation_images/ls/im_%s.jpg' %data_speed_2018[i])\n",
    "        i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###uncertainty calcualtion\n",
    "\n",
    "\n",
    "import glob\n",
    "filename=glob.glob(\"/DATA/hemapriya/uncertainty_7/predicted_mean*.csv\")\n",
    "data_un = []\n",
    "for i in filename:\n",
    "    data=pd.read_csv(i)\n",
    "    data_un += [data]\n",
    "y_mean_100 = np.hstack(data_un)\n",
    "print((y_mean_100).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_mean_101=pd.DataFrame(y_mean_100)\n",
    "y_mean_101.to_csv('/DATA/hemapriya/mean_100_models.csv')\n",
    "np.corrcoef(data_speed_2018,y_mean_100[:,20])[0,1]\n",
    "mean_pred=np.mean(y_mean_100,axis=1)\n",
    "std_pred=np.std(y_mean_100,axis=1)\n",
    "mean_pred1=np.mean(y_mean_100,axis=0)\n",
    "std_pred1=np.std(y_mean_100,axis=0)\n",
    "coeff1=[]\n",
    "for i in range(len(mean_pred1)):\n",
    "    coeff=np.corrcoef(data_speed_2018,y_mean_100[:,i])[0,1]\n",
    "    coeff1.append(coeff)\n",
    "mean=[]\n",
    "for i in range(len(mean_pred1)):\n",
    "    mean1=np.mean(y_mean_100[:,i])\n",
    "    mean.append(mean1)\n",
    "std=[]\n",
    "for i in range(len(mean_pred1)):\n",
    "    std1=np.std(y_mean_100[:,i])\n",
    "    std.append(std1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_pred1.min(),mean_pred1.max(),std_pred1.min(),std_pred1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSE=pd.read_csv('/DATA/hemapriya/HSE_CNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ace=HSE['start_ace']\n",
    "end_ace=HSE['end_ace']\n",
    "start_cnn=HSE['start_cnn']\n",
    "end_cnn=HSE['end_cnn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###testing peaks\n",
    "\n",
    "y_test1=pd.read_csv('/home/hemapriya/ML_SDO/y_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2=np.array(y_test1).reshape(4331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSE greater than 50 km/s- without threshold\n",
    "\n",
    "#HSE_automation\n",
    "\n",
    "y_test1=pd.read_csv('/home/hemapriya/ML_SDO/y_test1.csv')\n",
    "y_test1=np.array(y_test1).reshape(4331,)\n",
    "y_test_4d=np.array(pd.read_csv('\\home\\hemapriya\\ML_SDO\\y_test_4d.csv')).reshape(4331)\n",
    "data_ch=pd.read_csv('/home/hemapriya/ML_SDO/data.csv')\n",
    "data_ch_speed=data_ch.iloc[:,4]\n",
    "data_ch_speed1=data_ch_speed[0:8760:2]\n",
    "data_ch_speed2=np.array(data_ch_speed1[0:4331])\n",
    "data_2018_1=data_2018.iloc[:,3]\n",
    "data_2018_2=np.array(data_2018_1[0:4331])\n",
    "\n",
    "def HSE(data_speed_2018):\n",
    "    day=[]                 ##################3\n",
    "    for i in range(0,4306):\n",
    "        speed=data_speed_2018[i+12]-data_speed_2018[i]\n",
    "        if speed > 50:\n",
    "            day.append(i)\n",
    "    dayp=[]\n",
    "    for i in range(0,len(day)):          ###########excluding isolated points and grouping blocks\n",
    "        if (day[i]-day[i-1])<24:\n",
    "            dayp.append(day[i])\n",
    "    #finding start and end time of HSE\n",
    "    start_hse=[]\n",
    "    end_hse=[]\n",
    "    for j in range(len(dayp)):\n",
    "        if dayp[j]-dayp[j-1]>18:\n",
    "            end_hse.append(dayp[j-1])\n",
    "            start_hse.append(dayp[j])\n",
    "    start_hse=start_hse[0:(len(start_hse)-1)]\n",
    "    end_hse=end_hse[1:len(end_hse)]\n",
    "    sir_st=[]\n",
    "    v_min=[]\n",
    "    for i in start_hse:\n",
    "        data_min=np.argmin(data_speed_2018[i-24:i])\n",
    "        sir_st.append(i-24+data_min)\n",
    "        v_min.append(np.min(data_speed_2018[i-24:i]))\n",
    "    sir_en=[]\n",
    "    v_max=[]\n",
    "    for j in range(0,len(start_hse)):\n",
    "        data_max=np.argmax(data_speed_2018[start_hse[j]:(end_hse[j]+12)])\n",
    "        sir_en.append(start_hse[j]+data_max)\n",
    "        v_max.append(np.max(data_speed_2018[start_hse[j]:(end_hse[j]+12)])) \n",
    "\n",
    "    sir_stt=[]\n",
    "    sir_enn=[]\n",
    "    v_maxx=[]\n",
    "    v_minn=[]\n",
    "    for i in range(0,len(sir_st)):               ##removing sir's less than 0.5 day\n",
    "        if np.abs(sir_st[i]-sir_en[i])>6:\n",
    "            sir_stt.append(sir_st[i])\n",
    "            sir_enn.append(sir_en[i])\n",
    "            v_minn.append(v_min[i])\n",
    "            v_maxx.append(v_max[i])\n",
    "\n",
    "    return start_hse,end_hse,sir_stt,v_min,sir_enn,v_max\n",
    "#HSE for PS27 greater than 50 km/s- without threshold\n",
    "\n",
    "def HSE_27(data_speed_2018):\n",
    "    day=[]                 ##################3\n",
    "    for i in range(0,4044):\n",
    "        speed=data_speed_2018[i+12]-data_speed_2018[i]\n",
    "        if speed > 50:\n",
    "            day.append(i)\n",
    "    dayp=[]\n",
    "    for i in range(0,len(day)):          ###########excluding isolated points and grouping blocks\n",
    "        if (day[i]-day[i-1])<24:\n",
    "            dayp.append(day[i])\n",
    "    #finding start and end time of HSE\n",
    "    start_hse=[]\n",
    "    end_hse=[]\n",
    "    for j in range(len(dayp)):\n",
    "        if dayp[j]-dayp[j-1]>18:\n",
    "            end_hse.append(dayp[j-1])\n",
    "            start_hse.append(dayp[j])\n",
    "    start_hse=start_hse[0:(len(start_hse)-1)]\n",
    "    end_hse=end_hse[1:len(end_hse)]\n",
    "    sir_st=[]\n",
    "    v_min=[]\n",
    "    for i in start_hse:\n",
    "        data_min=np.argmin(data_speed_2018[i-24:i])\n",
    "        sir_st.append(i-24+data_min)\n",
    "        v_min.append(np.min(data_speed_2018[i-24:i]))\n",
    "    sir_en=[]\n",
    "    v_max=[]\n",
    "    for j in range(0,len(start_hse)):\n",
    "        data_max=np.argmax(data_speed_2018[start_hse[j]:(end_hse[j]+12)])\n",
    "        sir_en.append(start_hse[j]+data_max)\n",
    "        v_max.append(np.max(data_speed_2018[start_hse[j]:(end_hse[j]+12)])) \n",
    "\n",
    "    sir_stt=[]\n",
    "    sir_enn=[]\n",
    "    v_maxx=[]\n",
    "    v_minn=[]\n",
    "    for i in range(0,len(sir_st)):               ##removing sir's less than 0.5 day\n",
    "        if np.abs(sir_st[i]-sir_en[i])>6:\n",
    "            sir_stt.append(sir_st[i])\n",
    "            sir_enn.append(sir_en[i])\n",
    "            v_minn.append(v_min[i])\n",
    "            v_maxx.append(v_max[i])\n",
    "\n",
    "    return start_hse,end_hse,sir_stt,v_min,sir_enn,v_max,v_maxx,v_minn,data_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSE greater than 50 km/s- with threshold vmin<500 km/s and vmax>400 km/s\n",
    "\n",
    "def HSE_withthreshold(data_speed_2018):\n",
    "    day=[]                 ##################3\n",
    "    for i in range(0,4306):\n",
    "        speed=data_speed_2018[i+12]-data_speed_2018[i]\n",
    "        if speed > 50:\n",
    "            day.append(i)\n",
    "    dayp=[]\n",
    "    for i in range(0,len(day)):          ###########excluding isolated points and grouping blocks\n",
    "        if (day[i]-day[i-1])<24:\n",
    "            dayp.append(day[i])\n",
    "    #finding start and end time of HSE\n",
    "    start_hse=[]\n",
    "    end_hse=[]\n",
    "    for j in range(len(dayp)):\n",
    "        if dayp[j]-dayp[j-1]>18:\n",
    "            end_hse.append(dayp[j-1])\n",
    "            start_hse.append(dayp[j])\n",
    "    start_hse=start_hse[0:(len(start_hse)-1)]\n",
    "    end_hse=end_hse[1:len(end_hse)]\n",
    "    sir_st=[]\n",
    "    v_min=[]\n",
    "    for i in start_hse:\n",
    "        data_min=np.argmin(data_speed_2018[i-24:i])\n",
    "        sir_st.append(i-24+data_min)\n",
    "        v_min.append(np.min(data_speed_2018[i-24:i]))\n",
    "    sir_en=[]\n",
    "    v_max=[]\n",
    "    for j in range(0,len(start_hse)):\n",
    "        data_max=np.argmax(data_speed_2018[start_hse[j]:(end_hse[j]+12)])\n",
    "        sir_en.append(start_hse[j]+data_max)\n",
    "        v_max.append(np.max(data_speed_2018[start_hse[j]:(end_hse[j]+12)])) \n",
    "\n",
    "    sir_stt=[]\n",
    "    sir_enn=[]\n",
    "    v_maxx=[]\n",
    "    v_minn=[]\n",
    "    for i in range(0,len(sir_st)):               ##removing sir's less than 0.5 day\n",
    "        if np.abs(sir_st[i]-sir_en[i])>6:\n",
    "            if v_min[i]<500 and v_max[i]>400:\n",
    "                sir_stt.append(sir_st[i])\n",
    "                sir_enn.append(sir_en[i])\n",
    "                v_minn.append(v_min[i])\n",
    "                v_maxx.append(v_max[i])\n",
    "\n",
    "    return start_hse,end_hse,sir_stt,v_min,sir_enn,v_max,v_maxx,v_minn,data_max\n",
    "#HSE greater than 50 km/s- with threshold vmin<500 km/s and vmax>400 km/s\n",
    "\n",
    "def HSE_withthreshold_27(data_speed_2018):\n",
    "    day=[]                 ##################3\n",
    "    for i in range(0,4044):\n",
    "        speed=data_speed_2018[i+12]-data_speed_2018[i]\n",
    "        if speed > 50:\n",
    "            day.append(i)\n",
    "    dayp=[]\n",
    "    for i in range(0,len(day)):          ###########excluding isolated points and grouping blocks\n",
    "        if (day[i]-day[i-1])<24:\n",
    "            dayp.append(day[i])\n",
    "    #finding start and end time of HSE\n",
    "    start_hse=[]\n",
    "    end_hse=[]\n",
    "    for j in range(len(dayp)):\n",
    "        if dayp[j]-dayp[j-1]>18:\n",
    "            end_hse.append(dayp[j-1])\n",
    "            start_hse.append(dayp[j])\n",
    "    start_hse=start_hse[0:(len(start_hse)-1)]\n",
    "    end_hse=end_hse[1:len(end_hse)]\n",
    "    sir_st=[]\n",
    "    v_min=[]\n",
    "    for i in start_hse:\n",
    "        data_min=np.argmin(data_speed_2018[i-24:i])\n",
    "        sir_st.append(i-24+data_min)\n",
    "        v_min.append(np.min(data_speed_2018[i-24:i]))\n",
    "    sir_en=[]\n",
    "    v_max=[]\n",
    "    for j in range(0,len(start_hse)):\n",
    "        data_max=np.argmax(data_speed_2018[start_hse[j]:(end_hse[j]+12)])\n",
    "        sir_en.append(start_hse[j]+data_max)\n",
    "        v_max.append(np.max(data_speed_2018[start_hse[j]:(end_hse[j]+12)])) \n",
    "\n",
    "    sir_stt=[]\n",
    "    sir_enn=[]\n",
    "    v_maxx=[]\n",
    "    v_minn=[]\n",
    "    for i in range(0,len(sir_st)):               ##removing sir's less than 0.5 day\n",
    "        if np.abs(sir_st[i]-sir_en[i])>6:\n",
    "            if v_min[i]<500 and v_max[i]>400:\n",
    "                sir_stt.append(sir_st[i])\n",
    "                sir_enn.append(sir_en[i])\n",
    "                v_minn.append(v_min[i])\n",
    "                v_maxx.append(v_max[i])\n",
    "\n",
    "    return start_hse,end_hse,sir_stt,v_min,sir_enn,v_max,v_maxx,v_minn,data_max\n",
    "#defining hits and misses\n",
    "def hits_misses(sir_stt_p,sir_stt,sir_enn,sir_enn_p):\n",
    "    hits_po=0\n",
    "    hits_op=0\n",
    "    miss=0\n",
    "    false_alarm=0\n",
    "    v_max_p=[]\n",
    "    v_max_o=[]\n",
    "    for i in range(0,len(sir_stt_p)):\n",
    "        for j in range(0,len(sir_stt)):\n",
    "            if (sir_stt_p[i]>sir_stt[j] and sir_stt_p[i]<sir_enn[j]) or np.abs(sir_stt_p[i]-sir_stt[j])<12 :\n",
    "                hits_po=hits_po+1\n",
    "                v_max_p.append(v_maxx_p[i])\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0,len(sir_stt)):\n",
    "        for j in range(0,len(sir_stt_p)):\n",
    "            if (sir_stt[i]>sir_stt_p[j] and sir_stt[i]<sir_enn_p[j]) or np.abs(sir_stt[i]-sir_stt_p[j])<12 :\n",
    "                hits_op=hits_op+1\n",
    "                v_max_o.append(v_maxx[i])\n",
    "                break\n",
    "    return hits_op,hits_po\n",
    "#calculating metrics\n",
    "def metrics(hits,false_alarm,miss):\n",
    "    print(\"hits:\",hits,\"fa:\",false_alarm,\"miss:\",miss)\n",
    "    TS=hits/(hits+false_alarm+miss)\n",
    "    print(\"Threat_score:\",TS)\n",
    "    FAR=(false_alarm/(hits+false_alarm))*100\n",
    "    print(\"FAR:\",FAR)\n",
    "    PPV=(hits/(hits+false_alarm))*100\n",
    "    print(\"PPV:\",PPV)\n",
    "    bias=(hits+miss)/(hits+false_alarm)\n",
    "    print(\"bias:\",bias)\n",
    "    POD=(hits/(hits+miss))*100\n",
    "    print(\"POD:\",POD)\n",
    "    return TS,FAR,PPV,bias,POD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_hse_p,end_hse_p,sir_stt_p,v_min_p,sir_enn_p,v_max_p,v_maxx_p,v_minn_p,data_max_p=HSE_withthreshold(y_test1)\n",
    "start_hse,end_hse,sir_stt,v_min,sir_enn,v_max,v_maxx,v_minn,data_max=HSE_withthreshold(data_speed_2018)\n",
    "hits_op,hits_po=hits_misses(sir_stt_p,sir_stt,sir_enn,sir_enn_p)\n",
    "hits=max(hits_po,hits_op)\n",
    "false_alarm=len(sir_stt_p)-hits\n",
    "miss=len(sir_stt)-hits\n",
    "TS,FAR,PPV,bias,POD=metrics(hits,false_alarm,miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##HSE plot for CNN\n",
    "icme=[68,134,157,176,181,191,237,266]\n",
    "icme_h=[]\n",
    "for i in icme:\n",
    "    icme_h.append(i*12)\n",
    "\n",
    "fig, (ax1) = plt.subplots(figsize=(18,5),dpi=500)\n",
    "x = range(1,4332)\n",
    "for i in icme_h:\n",
    "    plt.axvline(x=i,ymin=0.9, ymax=1,linewidth=5.0,color='black')\n",
    "plt.plot(np.NaN, np.NaN, color='green',linewidth=5.0, label='ICME')\n",
    "month_starts = [1,384,732,1104,122*12,153*12,183*12,214*12,245*12,275*12,306*12,336*12]\n",
    "month_names = ['Jan','Feb','Mar','Apr','May','Jun',\n",
    "               'Jul','Aug','Sep','Oct','Nov','Dec'] \n",
    "\n",
    "for i,j in zip(sir_stt,sir_enn):\n",
    "    ax1.axvspan(i,j,ymin=0, ymax=1,color='green',alpha=0.2)\n",
    "\n",
    "    \n",
    "#plt.scatter(*zip(*v_max), color='green', label='max')\n",
    "ax1.plot(data_speed_2018,label='Observed',color='green')\n",
    "ax1.set_xticks(month_starts)\n",
    "ax1.set_xticklabels(month_names)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "\n",
    "for i,j in zip(sir_stt_p,sir_enn_p):\n",
    "    ax1.axvspan(i,j,ymin=0, ymax=1,color='red',alpha=0.2)\n",
    "\n",
    "\n",
    "#plt.scatter(*zip(*maxpeaks_act),color='red', label='max')\n",
    "ax1.plot(y_test1,label='CNN',color='red')\n",
    "ax1.set_xticks(month_starts)\n",
    "ax1.set_xticklabels(month_names)\n",
    "plt.xlabel('Time',fontsize=15)\n",
    "plt.ylabel('speed(Km/s)',fontsize=15)\n",
    "plt.xlabel(\"2018\")\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1)=plt.subplots(figsize=(18,5),dpi=500)\n",
    "x=np.arange(1,4332,1)\n",
    "icme=[68,134,157,176,181,191,237,266]\n",
    "icme_h=[]\n",
    "for i in icme:\n",
    "    icme_h.append(i*12)\n",
    "\n",
    "x = range(1,4332)\n",
    "for i in icme_h:\n",
    "    ax1.axvline(x=i,ymin=0.9, ymax=1,linewidth=5.0,color='black')\n",
    "plt.plot(np.NaN, np.NaN, color='black',linewidth=5.0, label='ICME')\n",
    "plt.plot(np.NaN, np.NaN, color='red',alpha=0.2,linewidth=5.0, label='predicted_HSE')\n",
    "plt.plot(np.NaN, np.NaN, color='green',alpha=0.2,linewidth=5.0, label='Observed_HSE')\n",
    "ax1.plot(x,data_speed_2018,label='ACE',color='green')\n",
    "ax1.plot(x,y_test1,label='CNN',color='red')\n",
    "for i,j in zip(sir_stt,sir_enn):\n",
    "    ax1.axvspan(i,j,ymin=0, ymax=1,color='green',alpha=0.2)\n",
    "for i,j in zip(sir_stt_p,sir_enn_p):\n",
    "    ax1.axvspan(i,j,ymin=0, ymax=1,color='red',alpha=0.2)\n",
    "month_starts = [1,384,732,1104,122*12,153*12,183*12,214*12,245*12,275*12,306*12,336*12]\n",
    "month_names = ['Jan','Feb','Mar','Apr','May','Jun',\n",
    "               'Jul','Aug','Sep','Oct','Nov','Dec'] \n",
    "ax1.set_xticks(month_starts)\n",
    "ax1.set_xticklabels(month_names)\n",
    "plt.xlabel('Time',fontsize=15)\n",
    "plt.ylabel('speed(Km/s)',fontsize=15)\n",
    "plt.xlabel(\"2018\")\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "ax2= plt.axes([.9,.9,.9,.9])\n",
    "ax2.plot(x[2000:245*12],data_speed_2018[2000:245*12],color='green')\n",
    "ax2.plot(x[2000:245*12],y_test1[2000:245*12],color='red')\n",
    "for i,j in zip(sir_stt[22:35],sir_enn[22:35]):\n",
    "    ax2.axvspan(i,j,ymin=0, ymax=1,color='green',alpha=0.2)\n",
    "for i,j in zip(sir_stt_p[20:28],sir_enn_p[20:28]):\n",
    "    ax2.axvspan(i,j,ymin=0, ymax=1,color='red',alpha=0.2)\n",
    "month_starts=[183*12,214*12,245*12]\n",
    "month_names=['Jun','Jul','Aug']\n",
    "plt.plot(np.NaN, np.NaN, color='red',alpha=0.2,linewidth=5.0, label='predicted_HSE')\n",
    "plt.plot(np.NaN, np.NaN, color='green',alpha=0.2,linewidth=5.0, label='Observed_HSE')\n",
    "ax2.set_xticks(month_starts)\n",
    "ax2.set_xticklabels(month_names)\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
